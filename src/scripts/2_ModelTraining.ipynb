{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3047a948-dbc4-48ee-8e39-8c26e886c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c3ed2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "dataset_directory = \"../processed/\"\n",
    "data = pd.read_csv(dataset_directory+\"aus.csv\")\n",
    "inputs = data.drop(\"Unnamed: 0\", axis=1)\n",
    "inputs = inputs.drop([\"input\",\"face\",\"frame\"],axis=1)\n",
    "\n",
    "inputs = inputs.dropna()\n",
    "\n",
    "inputs.head()\n",
    "\n",
    "labels = inputs[\"emotions\"]\n",
    "inputs = inputs.drop(\"emotions\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba817afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FaceRectX</th>\n",
       "      <th>FaceRectY</th>\n",
       "      <th>FaceRectWidth</th>\n",
       "      <th>FaceRectHeight</th>\n",
       "      <th>FaceScore</th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>...</th>\n",
       "      <th>AU26</th>\n",
       "      <th>AU28</th>\n",
       "      <th>AU43</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>25.736223</td>\n",
       "      <td>12.141386</td>\n",
       "      <td>184.504759</td>\n",
       "      <td>202.126955</td>\n",
       "      <td>0.997854</td>\n",
       "      <td>14.221463</td>\n",
       "      <td>12.755213</td>\n",
       "      <td>14.328785</td>\n",
       "      <td>21.170532</td>\n",
       "      <td>34.757541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379287</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>0.095835</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.143200e-04</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.661190</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.337242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>14.743028</td>\n",
       "      <td>2.997759</td>\n",
       "      <td>187.488326</td>\n",
       "      <td>207.703840</td>\n",
       "      <td>0.998749</td>\n",
       "      <td>7.541536</td>\n",
       "      <td>13.386972</td>\n",
       "      <td>21.044698</td>\n",
       "      <td>31.467807</td>\n",
       "      <td>47.116771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066171</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>0.434884</td>\n",
       "      <td>0.208928</td>\n",
       "      <td>0.024792</td>\n",
       "      <td>2.353687e-03</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.057586</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.700031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>8.470014</td>\n",
       "      <td>12.212509</td>\n",
       "      <td>192.603686</td>\n",
       "      <td>204.587296</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>6.174214</td>\n",
       "      <td>9.634752</td>\n",
       "      <td>14.608539</td>\n",
       "      <td>21.362039</td>\n",
       "      <td>33.840603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152316</td>\n",
       "      <td>0.508313</td>\n",
       "      <td>0.824280</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>7.806845e-07</td>\n",
       "      <td>0.986076</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.013316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>16.174509</td>\n",
       "      <td>14.903926</td>\n",
       "      <td>185.194891</td>\n",
       "      <td>203.781484</td>\n",
       "      <td>0.999118</td>\n",
       "      <td>7.937333</td>\n",
       "      <td>7.479537</td>\n",
       "      <td>9.962593</td>\n",
       "      <td>15.705766</td>\n",
       "      <td>27.800853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125997</td>\n",
       "      <td>0.389856</td>\n",
       "      <td>0.419714</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>1.017517e-04</td>\n",
       "      <td>0.986971</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.009645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>22.175928</td>\n",
       "      <td>-2.835185</td>\n",
       "      <td>191.182425</td>\n",
       "      <td>214.655604</td>\n",
       "      <td>0.998952</td>\n",
       "      <td>16.075465</td>\n",
       "      <td>13.695630</td>\n",
       "      <td>15.072491</td>\n",
       "      <td>22.049187</td>\n",
       "      <td>35.734631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157669</td>\n",
       "      <td>0.188250</td>\n",
       "      <td>0.039044</td>\n",
       "      <td>0.029047</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>2.646730e-03</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.166528</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.796034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>21.915174</td>\n",
       "      <td>14.619707</td>\n",
       "      <td>174.617022</td>\n",
       "      <td>198.709547</td>\n",
       "      <td>0.997993</td>\n",
       "      <td>19.748803</td>\n",
       "      <td>19.781839</td>\n",
       "      <td>21.229985</td>\n",
       "      <td>24.798247</td>\n",
       "      <td>33.727691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>0.529340</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>7.196333e-06</td>\n",
       "      <td>0.998514</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>18.808022</td>\n",
       "      <td>10.543539</td>\n",
       "      <td>189.865959</td>\n",
       "      <td>214.632669</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>15.768042</td>\n",
       "      <td>14.696542</td>\n",
       "      <td>15.879377</td>\n",
       "      <td>19.421814</td>\n",
       "      <td>29.609184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140021</td>\n",
       "      <td>0.309670</td>\n",
       "      <td>0.681390</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>7.314109e-05</td>\n",
       "      <td>0.997792</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>22.309469</td>\n",
       "      <td>12.064909</td>\n",
       "      <td>169.461908</td>\n",
       "      <td>195.683779</td>\n",
       "      <td>0.993389</td>\n",
       "      <td>22.860135</td>\n",
       "      <td>23.466042</td>\n",
       "      <td>27.300253</td>\n",
       "      <td>35.888995</td>\n",
       "      <td>46.786997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263751</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>0.064050</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.506478e-04</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.123477</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.875492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>20.305311</td>\n",
       "      <td>9.821847</td>\n",
       "      <td>185.389803</td>\n",
       "      <td>207.411780</td>\n",
       "      <td>0.998977</td>\n",
       "      <td>12.425982</td>\n",
       "      <td>11.786830</td>\n",
       "      <td>13.758410</td>\n",
       "      <td>19.872629</td>\n",
       "      <td>32.564612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122129</td>\n",
       "      <td>0.092681</td>\n",
       "      <td>0.155465</td>\n",
       "      <td>0.985851</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>5.906412e-03</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.000664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>21.836922</td>\n",
       "      <td>21.263691</td>\n",
       "      <td>181.526451</td>\n",
       "      <td>198.342785</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>18.090590</td>\n",
       "      <td>18.542497</td>\n",
       "      <td>20.471570</td>\n",
       "      <td>24.127807</td>\n",
       "      <td>32.495968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118506</td>\n",
       "      <td>0.096303</td>\n",
       "      <td>0.685978</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>9.942360e-05</td>\n",
       "      <td>0.996488</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.002885</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>895 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FaceRectX  FaceRectY  FaceRectWidth  FaceRectHeight  FaceScore  \\\n",
       "1236  25.736223  12.141386     184.504759      202.126955   0.997854   \n",
       "712   14.743028   2.997759     187.488326      207.703840   0.998749   \n",
       "364    8.470014  12.212509     192.603686      204.587296   0.999350   \n",
       "431   16.174509  14.903926     185.194891      203.781484   0.999118   \n",
       "846   22.175928  -2.835185     191.182425      214.655604   0.998952   \n",
       "...         ...        ...            ...             ...        ...   \n",
       "358   21.915174  14.619707     174.617022      198.709547   0.997993   \n",
       "468   18.808022  10.543539     189.865959      214.632669   0.999271   \n",
       "871   22.309469  12.064909     169.461908      195.683779   0.993389   \n",
       "93    20.305311   9.821847     185.389803      207.411780   0.998977   \n",
       "520   21.836922  21.263691     181.526451      198.342785   0.998924   \n",
       "\n",
       "            x_0        x_1        x_2        x_3        x_4  ...      AU26  \\\n",
       "1236  14.221463  12.755213  14.328785  21.170532  34.757541  ...  0.379287   \n",
       "712    7.541536  13.386972  21.044698  31.467807  47.116771  ...  0.066171   \n",
       "364    6.174214   9.634752  14.608539  21.362039  33.840603  ...  0.152316   \n",
       "431    7.937333   7.479537   9.962593  15.705766  27.800853  ...  0.125997   \n",
       "846   16.075465  13.695630  15.072491  22.049187  35.734631  ...  0.157669   \n",
       "...         ...        ...        ...        ...        ...  ...       ...   \n",
       "358   19.748803  19.781839  21.229985  24.798247  33.727691  ...  0.056478   \n",
       "468   15.768042  14.696542  15.879377  19.421814  29.609184  ...  0.140021   \n",
       "871   22.860135  23.466042  27.300253  35.888995  46.786997  ...  0.263751   \n",
       "93    12.425982  11.786830  13.758410  19.872629  32.564612  ...  0.122129   \n",
       "520   18.090590  18.542497  20.471570  24.127807  32.495968  ...  0.118506   \n",
       "\n",
       "          AU28      AU43     anger   disgust          fear  happiness  \\\n",
       "1236  0.048427  0.095835  0.000573  0.000086  1.143200e-04   0.000360   \n",
       "712   0.345989  0.434884  0.208928  0.024792  2.353687e-03   0.004968   \n",
       "364   0.508313  0.824280  0.000281  0.000005  7.806845e-07   0.986076   \n",
       "431   0.389856  0.419714  0.001103  0.000373  1.017517e-04   0.986971   \n",
       "846   0.188250  0.039044  0.029047  0.002627  2.646730e-03   0.001942   \n",
       "...        ...       ...       ...       ...           ...        ...   \n",
       "358   0.529340  0.715230  0.000660  0.000050  7.196333e-06   0.998514   \n",
       "468   0.309670  0.681390  0.000142  0.000053  7.314109e-05   0.997792   \n",
       "871   0.021937  0.064050  0.000167  0.000025  2.506478e-04   0.000231   \n",
       "93    0.092681  0.155465  0.985851  0.004189  5.906412e-03   0.000021   \n",
       "520   0.096303  0.685978  0.000044  0.000041  9.942360e-05   0.996488   \n",
       "\n",
       "       sadness  surprise   neutral  \n",
       "1236  0.661190  0.000435  0.337242  \n",
       "712   0.057586  0.001341  0.700031  \n",
       "364   0.000312  0.000009  0.013316  \n",
       "431   0.000895  0.000912  0.009645  \n",
       "846   0.166528  0.001175  0.796034  \n",
       "...        ...       ...       ...  \n",
       "358   0.000375  0.000251  0.000143  \n",
       "468   0.000994  0.000319  0.000627  \n",
       "871   0.123477  0.000357  0.875492  \n",
       "93    0.001594  0.001774  0.000664  \n",
       "520   0.000298  0.002885  0.000145  \n",
       "\n",
       "[895 rows x 171 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# split = 70/20/10\n",
    "data_in, test_in, data_out, test_out = train_test_split(\n",
    "    inputs,\n",
    "    labels,\n",
    "    test_size=0.1,\n",
    "    random_state=18,\n",
    "    stratify=labels,  # balances labels across the sets\n",
    ")\n",
    "\n",
    "train_in, val_in, train_out, val_out = train_test_split(\n",
    "    data_in,\n",
    "    data_out,\n",
    "    test_size=(0.2 / 0.9),  # 20% of the original data\n",
    "    random_state=18,\n",
    "    stratify=data_out,\n",
    ")\n",
    "train_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44cde23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'svc__C': 0.1, 'svc__class_weight': None, 'svc__gamma': 'scale', 'svc__kernel': 'linear'}\n",
      "Best Cross-Validation Score: 0.7385474860335195\n",
      "Validation Set Accuracy: 0.78125\n",
      "Test Set Accuracy: 0.7421875\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.60      0.50      0.55        18\n",
      "     disgust       0.50      0.56      0.53         9\n",
      "        fear       1.00      0.29      0.44         7\n",
      "       happy       0.97      0.94      0.95        33\n",
      "     neutral       0.67      0.94      0.79        35\n",
      "         sad       0.71      0.62      0.67         8\n",
      "    surprise       0.77      0.56      0.65        18\n",
      "\n",
      "    accuracy                           0.74       128\n",
      "   macro avg       0.75      0.63      0.65       128\n",
      "weighted avg       0.76      0.74      0.73       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model 2 svc rbl\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create Pipeline with SVC\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        # Step 1: Preprocessing - Standardize features\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        # Step 2: Model - Support Vector Classifier\n",
    "        (\"svc\", SVC(probability=True)),  # probability=True for prediction probabilities\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define Hyperparameter Grid for Tuning\n",
    "param_grid = {\n",
    "    # Hyperparameters for the SVC\n",
    "    \"svc__C\": [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    \"svc__kernel\": [\"linear\", \"rbf\", \"poly\"],  # Kernel type\n",
    "    \"svc__gamma\": [\"scale\", \"auto\", 0.1, 1],  # Kernel coefficient\n",
    "    \"svc__class_weight\": [None, \"balanced\"],  # Handle class imbalance\n",
    "}\n",
    "\n",
    "# Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,  # The pipeline we created\n",
    "    param_grid,  # Hyperparameter combinations to try\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring=\"accuracy\",  # Metric to evaluate\n",
    "    n_jobs=-1,  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the grid search on training data\n",
    "grid_search.fit(train_in, train_out)\n",
    "\n",
    "# Best model and parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
    "\n",
    "# Validate on validation set\n",
    "val_score = grid_search.score(val_in, val_out)\n",
    "print(\"Validation Set Accuracy:\", val_score)\n",
    "\n",
    "# Final evaluation on test set\n",
    "test_score = grid_search.score(test_in, test_out)\n",
    "print(\"Test Set Accuracy:\", test_score)\n",
    "\n",
    "# Optional: Detailed Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = best_model.predict(test_in)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_out, y_pred))\n",
    "\n",
    "# Optional: Prediction probabilities\n",
    "y_pred_proba = best_model.predict_proba(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a9d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineLearningWorkflow:\n",
    "    def __init__(self, data_path, target_column):\n",
    "        \"\"\"\n",
    "        Initialize the machine learning workflow\n",
    "\n",
    "        Args:\n",
    "            data_path (str): Path to the dataset\n",
    "            target_column (str): Name of the target column\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.target_column = target_column\n",
    "        self.data = None\n",
    "        self.X_train = None\n",
    "        self.X_val = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_val = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def prepare_dataset(self, test_size=0.1, val_size=(0.2 / 0.9), random_state=42):\n",
    "        \"\"\"\n",
    "        Prepare the dataset by loading and splitting\n",
    "\n",
    "        Args:\n",
    "            test_size (float): Proportion of test set\n",
    "            val_size (float): Proportion of validation set\n",
    "            random_state (int): Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        # Load data\n",
    "        self.data = pd.read_csv(self.data_path)\n",
    "\n",
    "        # Display class distribution\n",
    "        print(\"Class Distribution:\")\n",
    "        print(self.data[self.target_column].value_counts())\n",
    "\n",
    "        # Separate features and target\n",
    "\n",
    "        features = self.data.dropna()\n",
    "        features = features.drop([\"input\", \"face\", \"frame\", \"Unnamed: 0\"], axis=1)\n",
    "        labels = features[self.target_column]\n",
    "\n",
    "        au_columns = [col for col in features.columns if col.startswith(\"AU\")]\n",
    "        features = features[au_columns]\n",
    "        print(features)\n",
    "\n",
    "        \n",
    "\n",
    "        # First split\n",
    "        X_temp, self.X_test, y_temp, self.y_test = train_test_split(\n",
    "            features,\n",
    "            labels,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=labels,\n",
    "        )\n",
    "\n",
    "        # Second split\n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
    "            X_temp, y_temp, test_size=val_size, random_state=random_state\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def create_preprocessing_pipeline(self):\n",
    "        \"\"\"\n",
    "        Create a preprocessing pipeline with imputation and scaling\n",
    "\n",
    "        Returns:\n",
    "            Pipeline: Preprocessing pipeline\n",
    "        \"\"\"\n",
    "        preprocessing_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return preprocessing_pipeline\n",
    "\n",
    "    def evaluate_model(self, model, X_val, y_val):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "\n",
    "        Args:\n",
    "            model: Trained model\n",
    "            X_val: Validation features\n",
    "            y_val: Validation labels\n",
    "\n",
    "        Returns:\n",
    "            dict: Performance metrics\n",
    "        \"\"\"\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy_score(y_val, y_pred),\n",
    "            \"precision\": precision_score(y_val, y_pred, average=\"weighted\"),\n",
    "            \"recall\": recall_score(y_val, y_pred, average=\"weighted\"),\n",
    "            \"f1_score\": f1_score(y_val, y_pred, average=\"weighted\"),\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def tune_model_hyperparameters(self, model_class, param_grid):\n",
    "        \"\"\"\n",
    "        Tune hyperparameters for a given model\n",
    "\n",
    "        Args:\n",
    "            model_class: Model class to tune\n",
    "            param_grid (dict): Hyperparameter grid\n",
    "\n",
    "        Returns:\n",
    "            RandomizedSearchCV: Best model after hyperparameter tuning\n",
    "        \"\"\"\n",
    "        full_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"preprocessor\", self.create_preprocessing_pipeline()),\n",
    "                (\"classifier\", model_class()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        random_search = RandomizedSearchCV(\n",
    "            full_pipeline,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=50,\n",
    "            cv=5,\n",
    "            scoring=\"accuracy\",\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        random_search.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print(f\"Best parameters for {model_class.__name__}:\")\n",
    "        print(random_search.best_params_)\n",
    "\n",
    "        return random_search\n",
    "\n",
    "    def train_and_compare_models(self):\n",
    "        \"\"\"\n",
    "        Train multiple models and compare their performance\n",
    "\n",
    "        Returns:\n",
    "            dict: Models with their performance metrics\n",
    "        \"\"\"\n",
    "        # Define models and their hyperparameter grids\n",
    "        models = {\n",
    "            \"RandomForest\": {\n",
    "                \"class\": RandomForestClassifier,\n",
    "                \"params\": {\n",
    "                    \"classifier__n_estimators\": [100, 200, 300],\n",
    "                    \"classifier__max_depth\": [10, 20, 30, None],\n",
    "                },\n",
    "            },\n",
    "            \"SVM\": {\n",
    "                \"class\": SVC,\n",
    "                \"params\": {\n",
    "                    \"classifier__kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n",
    "                    \"classifier__C\": [0.1, 1, 10, 100],\n",
    "                },\n",
    "            },\n",
    "            \"DecisionTree\": {\n",
    "                \"class\": DecisionTreeClassifier,\n",
    "                \"params\": {\n",
    "                    \"classifier__max_depth\": [5, 10, 15, 20],\n",
    "                    \"classifier__min_samples_split\": [2, 5, 10],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "        model_performances = {}\n",
    "\n",
    "        for name, model_config in models.items():\n",
    "            print(f\"\\nTuning {name} Model\")\n",
    "            tuned_model = self.tune_model_hyperparameters(\n",
    "                model_config[\"class\"], model_config[\"params\"]\n",
    "            )\n",
    "\n",
    "            # Evaluate on validation set\n",
    "            metrics = self.evaluate_model(\n",
    "                tuned_model.best_estimator_, self.X_val, self.y_val\n",
    "            )\n",
    "\n",
    "            model_performances[name] = {\n",
    "                \"best_model\": tuned_model.best_estimator_,\n",
    "                \"metrics\": metrics,\n",
    "            }\n",
    "\n",
    "        return model_performances\n",
    "\n",
    "    def select_best_model(self, model_performances):\n",
    "        \"\"\"\n",
    "        Select the best model based on accuracy\n",
    "\n",
    "        Args:\n",
    "            model_performances (dict): Dictionary of model performances\n",
    "\n",
    "        Returns:\n",
    "            tuple: Best model and its name\n",
    "        \"\"\"\n",
    "        best_model_name = max(\n",
    "            model_performances,\n",
    "            key=lambda k: model_performances[k][\"metrics\"][\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        best_model = model_performances[best_model_name][\"best_model\"]\n",
    "        best_accuracy = model_performances[best_model_name][\"metrics\"][\"accuracy\"]\n",
    "\n",
    "        print(f\"\\nBest Model: {best_model_name}\")\n",
    "        print(f\"Validation Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "        return best_model, best_model_name\n",
    "\n",
    "    def save_best_model(self, best_model, best_model_name, save_dir=\"../model/\"):\n",
    "        \"\"\"\n",
    "        Save the best performing model\n",
    "\n",
    "        Args:\n",
    "            best_model: Best trained model\n",
    "            best_model_name (str): Name of the best model\n",
    "            save_dir (str): Directory to save the model\n",
    "        \"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        model_filename = f\"best_emotion_model_{best_model_name}.pkl\"\n",
    "        model_path = os.path.join(save_dir, model_filename)\n",
    "\n",
    "        joblib.dump(best_model, model_path)\n",
    "        print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc29f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "emotions\n",
      "neutral     348\n",
      "happy       340\n",
      "surprise    182\n",
      "angry       178\n",
      "disgust      88\n",
      "sad          81\n",
      "fear         72\n",
      "Name: count, dtype: int64\n",
      "          AU01      AU02      AU04      AU05      AU06  AU07      AU09  \\\n",
      "0     0.462118  0.187764  0.578946  0.328081  0.538130   1.0  0.535241   \n",
      "1     0.360411  0.191716  0.247170  0.269536  0.079867   0.0  0.259076   \n",
      "2     0.183939  0.150695  0.490818  0.274774  0.653131   1.0  0.636941   \n",
      "3     0.561900  0.431248  0.545331  0.438458  0.145115   0.0  0.367367   \n",
      "4     0.437871  0.435552  0.651622  0.320687  0.240153   1.0  0.413129   \n",
      "...        ...       ...       ...       ...       ...   ...       ...   \n",
      "1284  0.241089  0.370427  0.334878  0.328424  0.122249   0.0  0.330490   \n",
      "1285  0.397340  0.158596  0.353561  0.404856  0.127621   1.0  0.411720   \n",
      "1286  0.309860  0.305702  0.351745  0.406746  0.100878   1.0  0.240786   \n",
      "1287  0.387912  0.216832  0.701315  0.353338  0.193991   0.0  0.504722   \n",
      "1288  0.346435  0.167175  0.347798  0.355166  0.160812   1.0  0.368918   \n",
      "\n",
      "          AU10  AU11      AU12      AU14      AU15      AU17  AU20      AU23  \\\n",
      "0     0.017864   0.0  0.468818  0.372400  0.113740  0.220734   1.0  0.408252   \n",
      "1     0.002263   1.0  0.055227  0.388238  0.137423  0.408483   0.0  0.341253   \n",
      "2     0.439596   1.0  0.728171  0.351749  0.382685  0.379113   1.0  0.302866   \n",
      "3     0.017376   0.0  0.203837  0.227149  0.325409  0.405293   0.0  0.618190   \n",
      "4     0.048525   0.0  0.253516  0.257582  0.290868  0.371060   1.0  0.571588   \n",
      "...        ...   ...       ...       ...       ...       ...   ...       ...   \n",
      "1284  0.525239   0.0  0.185672  0.721279  0.320155  0.235063   1.0  0.518204   \n",
      "1285  0.390705   1.0  0.157700  0.196211  0.117685  0.382626   1.0  0.508391   \n",
      "1286  0.280651   0.0  0.064968  0.171804  0.121845  0.340176   1.0  0.691530   \n",
      "1287  0.058126   0.0  0.209901  0.265109  0.544971  0.367894   1.0  0.694494   \n",
      "1288  0.067416   0.0  0.136731  0.262040  0.100099  0.388635   1.0  0.645398   \n",
      "\n",
      "          AU24      AU25      AU26      AU28      AU43  \n",
      "0     0.015889  0.997768  0.425320  0.071662  0.329757  \n",
      "1     0.210279  0.110672  0.080882  0.039017  0.135750  \n",
      "2     0.463770  0.993779  0.503689  0.016873  0.548190  \n",
      "3     0.240980  0.455606  0.154259  0.526159  0.218896  \n",
      "4     0.283109  0.889205  0.081161  0.233515  0.375295  \n",
      "...        ...       ...       ...       ...       ...  \n",
      "1284  0.096220  0.986997  0.621995  0.025592  0.157782  \n",
      "1285  0.251441  0.963028  0.156766  0.064117  0.133677  \n",
      "1286  0.167721  0.570192  0.127037  0.091988  0.321708  \n",
      "1287  0.345959  0.742798  0.284439  0.256714  0.387887  \n",
      "1288  0.070924  0.998777  0.849085  0.359869  0.360416  \n",
      "\n",
      "[1279 rows x 20 columns]\n",
      "\n",
      "Tuning RandomForest Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amrit\\env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for RandomForestClassifier:\n",
      "{'classifier__n_estimators': 300, 'classifier__max_depth': 20}\n",
      "\n",
      "Tuning SVM Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amrit\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\amrit\\env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVC:\n",
      "{'classifier__kernel': 'rbf', 'classifier__C': 1}\n",
      "\n",
      "Tuning DecisionTree Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amrit\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\amrit\\env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for DecisionTreeClassifier:\n",
      "{'classifier__min_samples_split': 5, 'classifier__max_depth': 5}\n",
      "\n",
      "Best Model: SVM\n",
      "Validation Accuracy: 0.6680\n",
      "Model saved to ../model/best_emotion_model_SVM.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amrit\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import joblib\n",
    "\n",
    "\n",
    "workflow = MachineLearningWorkflow(\n",
    "    data_path=dataset_directory + \"aus.csv\", target_column=\"emotions\"\n",
    ")\n",
    "\n",
    "workflow.prepare_dataset()\n",
    "model_performances = workflow.train_and_compare_models()\n",
    "best_model, best_model_name = workflow.select_best_model(model_performances)\n",
    "workflow.save_best_model(best_model, best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275db0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
