{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f2227d-2a39-471e-97b0-e35567c85592",
   "metadata": {},
   "source": [
    "Furhat bartender  A  User Perception  sub-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be520cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model 2 svc rbl\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "model_2 = SVC(kernel='rbf' , C= 1)\n",
    "X_train_scaled = sc.fit_transform(train_in)\n",
    "X_test_scaled = sc.transform(val_in)\n",
    "model_2.fit(X_train_scaled, train_out)\n",
    "predicted_val = model_2.predict(X_test_scaled)\n",
    "accuracy_score(val_out, predicted_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1253239-c165-4487-bc24-3d38252928d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from furhat_remote_api import FurhatRemoteAPI \n",
    "import cv2\n",
    "import opencv_jupyter_ui as jcv2\n",
    "from feat import Detector\n",
    "from IPython.display import Image\n",
    "\n",
    "from feat.utils import FEAT_EMOTION_COLUMNS\n",
    "\n",
    "import imageio.v3 as iio\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image, Video\n",
    "from feat import Detector\n",
    "import opencv_jupyter_ui as jcv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import time\n",
    "\n",
    "# import useful libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c540fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#furhhat init\n",
    "furhat = FurhatRemoteAPI(\"localhost\")\n",
    "voices = furhat.get_voices()\n",
    "gestures = furhat.get_gestures()\n",
    "print(gestures)\n",
    "# Select a character for the virtual Furhat\n",
    "furhat.set_face(character=\"Isabel\", mask=\"adult\")\n",
    "# Set the voice of the robot\n",
    "furhat.set_voice(name=\"Joanna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a66cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "detector = Detector(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8178f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"OpenCV found an error reading the next frame.\")\n",
    "        break\n",
    "\n",
    "    jcv2.imshow(\"Emotion Detection\", frame)\n",
    "    prediction = detector.detect_faces(frame)\n",
    "    prediction\n",
    "    time.sleep(10)\n",
    "\n",
    "\n",
    "    key = jcv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # ESC pressed\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "jcv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10262d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from feat import Detector\n",
    "import time\n",
    "\n",
    "# Initialize the facial action unit detector\n",
    "detector = Detector(\n",
    "    face_model=\"retinaface\",\n",
    "    landmark_model=\"mobilenet\",\n",
    "    au_model=\"xgb\",\n",
    "    emotion_model=\"resmasknet\",\n",
    "    device=\"gpu\",\n",
    ")\n",
    "\n",
    "# Open webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "while True:\n",
    "    # Capture frame\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "\n",
    "    # Detect faces and get action units\n",
    "    predictions = detector.detect_faces(frame)\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow(\"Facial Action Units\", frame)\n",
    "\n",
    "    # Break on ESC key\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # ESC key\n",
    "        break\n",
    "\n",
    "    # Small delay to prevent overwhelming processing\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Cleanup\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de02761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
