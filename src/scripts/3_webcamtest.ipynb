{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccdfc705",
   "metadata": {},
   "source": [
    "# detect emotion using webcam test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import joblib\n",
    "from feat import Detector\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import opencv_jupyter_ui as jcv2\n",
    "\n",
    "model_path = \"../model/\"\n",
    "# Load the pre-trained RandomForest model\n",
    "model_pkl = \"best_emotion_model_SVM.pkl\"\n",
    "# Initialize the detector\n",
    "detector = Detector(device=\"cuda\")\n",
    "\n",
    "# Emotion label mapping based on your training data\n",
    "emotion_labels = {\n",
    "    0: \"neutral\",\n",
    "    1: \"happy\",\n",
    "    2: \"sad\",\n",
    "    3: \"surprise\",\n",
    "    4: \"fear\",\n",
    "    5: \"disgust\",\n",
    "    6: \"angry\",\n",
    "}\n",
    "\n",
    "\n",
    "def extract_features(frame, detector):\n",
    "    # Convert frame to format expected by py-feat (PIL Image)\n",
    "    frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Detect faces and extract features\n",
    "    detections = detector.detect_faces(frame_pil)\n",
    "    if len(detections) == 0:\n",
    "        return None\n",
    "\n",
    "    detected_landmarks = detector.detect_landmarks(frame, detections)\n",
    "\n",
    "    # Assuming that the model was trained using the features from the first detected face\n",
    "    if len(detected_landmarks) > 0:\n",
    "        aus = detector.detect_aus(frame_pil, detected_landmarks)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # Check if AUs are extracted and handle the structure\n",
    "    if isinstance(aus, list) and len(aus) > 0:\n",
    "        # Flatten the structure if it's a nested list or array\n",
    "        # and ensure only the expected number of features are returned\n",
    "        aus_flat = np.array(aus[0]).flatten()[\n",
    "            :20\n",
    "        ]  # Adjust number of features if needed\n",
    "        return aus_flat\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load(model_path+model_pkl)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set desired FPS\n",
    "desired_fps = 10  # Adjust as needed\n",
    "frame_interval = 1 / desired_fps\n",
    "\n",
    "last_time = time.time()\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Control frame rate\n",
    "    current_time = time.time()\n",
    "    if current_time - last_time < frame_interval:\n",
    "        continue\n",
    "    last_time = current_time\n",
    "\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame and extract features\n",
    "    features = extract_features(frame, detector)\n",
    "\n",
    "    # Check if features are extracted\n",
    "    if features is not None and len(features) > 0:\n",
    "        # Predict emotion\n",
    "        emotion = model.predict([features])[0]\n",
    "        #emotion = emotion_labels.get(emotion, \"Unknown\")\n",
    "\n",
    "        # Display the result\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"Emotion: {emotion}\",\n",
    "            (10, 50),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    jcv2.imshow(\"Emotion Detection\", frame)\n",
    "\n",
    "    key = jcv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # ESC pressed\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "jcv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
